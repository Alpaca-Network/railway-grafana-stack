{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": "-- Grafana --",
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "description": "GatewayZ Four Golden Signals \u2014 SRE observability covering Latency, Traffic, Errors, and Saturation (the four pillars of service reliability). Never rely on averages \u2014 they hide the misery of your slowest users.",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": null,
  "links": [
    {
      "asDropdown": true,
      "icon": "doc",
      "includeVars": true,
      "tags": [
        "gatewayz"
      ],
      "targetBlank": false,
      "title": "Related Dashboards",
      "type": "dashboards"
    }
  ],
  "tags": [
    "gatewayz",
    "sre",
    "golden-signals"
  ],
  "panels": [
    {
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "gridPos": {
        "h": 6,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 1,
      "options": {
        "code": {
          "language": "plaintext",
          "showLineNumbers": false,
          "showMiniMap": false
        },
        "content": "## GatewayZ \u2014 AI Inference Gateway Health\nThis dashboard answers one question: **is the gateway healthy enough to route LLM requests right now?** It is the first screen to open during an incident and the last to close when the incident ends.\n\n| Pillar | What it measures for GatewayZ specifically |\n|--------|--------------------------------------------|\n| **\u26a1 Latency** | Round-trip from client request \u2192 gateway response. Dominated by provider inference time \u2014 P99 can legitimately exceed 30 s for long-generation streaming. The poison-check panel isolates 5xx responses so a wave of instant provider rejections does not drag the success percentiles down. |\n| **\ud83d\udea6 Traffic** | Inbound LLM requests per second. Each request may hold an open connection for the full streaming duration, so RPS alone understates concurrency. A gap between total RPS and success RPS tells you how much capacity errors are wasting. |\n| **\ud83d\udea8 Errors** | Three kinds: **explicit** (5xx the gateway emits), **policy** (200 OK responses that took longer than the 2 s SLO \u2014 valid for short completions, not for streaming), **client** (4xx \u2014 mostly rate-limit hits from the 40 k+ trial users managed in Redis). |\n| **\ud83d\udcca Saturation** | Redis is the single most constrained shared resource. It enforces rate limits, caches the model catalog, and tracks trial-user state. When Redis memory approaches its cap, keys are evicted silently \u2014 rate limiting breaks without raising an explicit error. |",
        "mode": "markdown"
      },
      "pluginVersion": "11.5.2",
      "title": "",
      "transparent": true,
      "type": "text"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 6
      },
      "id": 10,
      "panels": [],
      "title": "\u26a1  Pillar I \u2014 Latency (The Speed Pillar)  |  Successful Requests vs HTTP 5xx \u2014 P50 / P95 / P99 only, no averages",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.3
              },
              {
                "color": "red",
                "value": 0.8
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 0,
        "y": 7
      },
      "id": 11,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": false,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum(rate(fastapi_requests_duration_seconds_bucket{status_code!~\"5..\"}[5m])) by (le))",
          "legendFormat": "P50 (success)",
          "refId": "A"
        }
      ],
      "title": "P50 Latency \u2014 Successful",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 1.0
              },
              {
                "color": "red",
                "value": 2.0
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 6,
        "y": 7
      },
      "id": 12,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": false,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(fastapi_requests_duration_seconds_bucket{status_code!~\"5..\"}[5m])) by (le))",
          "legendFormat": "P95 (success)",
          "refId": "A"
        }
      ],
      "title": "P95 Latency \u2014 Successful",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 2.0
              },
              {
                "color": "red",
                "value": 5.0
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 12,
        "y": 7
      },
      "id": 13,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": false,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "histogram_quantile(0.99, sum(rate(fastapi_requests_duration_seconds_bucket{status_code!~\"5..\"}[5m])) by (le))",
          "legendFormat": "P99 (success)",
          "refId": "A"
        }
      ],
      "title": "P99 Latency \u2014 Successful (Tail)",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "noValue": "No 5xx traffic",
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "orange",
                "value": 0.1
              },
              {
                "color": "red",
                "value": 0.5
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 18,
        "y": 7
      },
      "id": 14,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": false,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(fastapi_requests_duration_seconds_bucket{status_code=~\"5..\"}[5m])) by (le))",
          "legendFormat": "P95 (5xx errors)",
          "refId": "A"
        }
      ],
      "title": "P95 Latency \u2014 HTTP 5xx (Poison Check)",
      "description": "P95 of only failed (5xx) requests. A low value here means errors are failing fast (good). A high value means errors are also slow \u2014 double punishment for your users.",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisColorMode": "text",
            "axisLabel": "Latency (seconds)",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 15,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 4,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "line+area",
              "fill": "below"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "transparent",
                "value": null
              },
              {
                "color": "rgba(255, 152, 0, 0.1)",
                "value": 2.0
              }
            ]
          },
          "unit": "s"
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "P50 \u2014 Success"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "#73BF69",
                  "mode": "fixed"
                }
              },
              {
                "id": "custom.lineWidth",
                "value": 2
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "P95 \u2014 Success"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "#FADE2A",
                  "mode": "fixed"
                }
              },
              {
                "id": "custom.lineWidth",
                "value": 2
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "P99 \u2014 Success (Tail)"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "#FF9830",
                  "mode": "fixed"
                }
              },
              {
                "id": "custom.lineWidth",
                "value": 2
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "P95 \u2014 HTTP 5xx (Poison)"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "#F2495C",
                  "mode": "fixed"
                }
              },
              {
                "id": "custom.lineStyle",
                "value": {
                  "dash": [
                    4,
                    4
                  ],
                  "fill": "dash"
                }
              },
              {
                "id": "custom.lineWidth",
                "value": 2
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 9,
        "w": 24,
        "x": 0,
        "y": 11
      },
      "id": 15,
      "options": {
        "legend": {
          "calcs": [
            "mean",
            "max",
            "lastNotNull"
          ],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum(rate(fastapi_requests_duration_seconds_bucket{status_code!~\"5..\"}[5m])) by (le))",
          "legendFormat": "P50 \u2014 Success",
          "refId": "A"
        },
        {
          "expr": "histogram_quantile(0.95, sum(rate(fastapi_requests_duration_seconds_bucket{status_code!~\"5..\"}[5m])) by (le))",
          "legendFormat": "P95 \u2014 Success",
          "refId": "B"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(fastapi_requests_duration_seconds_bucket{status_code!~\"5..\"}[5m])) by (le))",
          "legendFormat": "P99 \u2014 Success (Tail)",
          "refId": "C"
        },
        {
          "expr": "histogram_quantile(0.95, sum(rate(fastapi_requests_duration_seconds_bucket{status_code=~\"5..\"}[5m])) by (le))",
          "legendFormat": "P95 \u2014 HTTP 5xx (Poison)",
          "refId": "D"
        }
      ],
      "title": "Latency Percentiles Over Time \u2014 Success vs 5xx Errors",
      "description": "Dashed red line shows the P95 of failed (5xx) requests. If this line spikes independently of the success lines, errors are triggering immediately and poisoning your overall latency average \u2014 exactly why we never trust the mean.",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 20
      },
      "id": 20,
      "panels": [],
      "title": "\ud83d\udea6  Pillar II \u2014 Traffic (The Demand Pillar)  |  Distinguishes capacity problems from code problems",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 50
              },
              {
                "color": "red",
                "value": 200
              }
            ]
          },
          "unit": "reqps"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 0,
        "y": 21
      },
      "id": 21,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": true,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "sum(rate(fastapi_requests_total[5m]))",
          "legendFormat": "Total RPS",
          "refId": "A"
        }
      ],
      "title": "HTTP Request Rate (RPS)",
      "description": "Total inbound requests per second across all endpoints and HTTP methods.",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "blue",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 6,
        "y": 21
      },
      "id": 22,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": false,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "sum(increase(fastapi_requests_total[5m]))",
          "legendFormat": "Requests",
          "refId": "A"
        }
      ],
      "title": "Total Requests (last 5 min)",
      "description": "Absolute count of requests received in the last 5-minute window. Use alongside RPS for traffic shape analysis.",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 40
              },
              {
                "color": "red",
                "value": 150
              }
            ]
          },
          "unit": "reqps"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 12,
        "y": 21
      },
      "id": 23,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": true,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "sum(rate(fastapi_requests_total{status_code!~\"5..\"}[5m]))",
          "legendFormat": "Success RPS",
          "refId": "A"
        }
      ],
      "title": "Successful Request Rate (RPS)",
      "description": "RPS for only non-5xx responses. Compare with total RPS \u2014 a large gap means errors are eating into real capacity.",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "noValue": "Metric not instrumented",
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "blue",
                "value": null
              },
              {
                "color": "yellow",
                "value": 5000000
              },
              {
                "color": "red",
                "value": 50000000
              }
            ]
          },
          "unit": "Bps"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 18,
        "y": 21
      },
      "id": 24,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": false,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "sum(rate(fastapi_request_size_bytes_sum[5m])) or sum(rate(fastapi_response_size_bytes_sum[5m])) or vector(0)",
          "legendFormat": "Bandwidth",
          "refId": "A"
        }
      ],
      "title": "Inbound Bandwidth (bytes/sec)",
      "description": "Data volume flowing into the service per second. Critical for data-heavy workloads (LLM token streams). Requires request_size instrumentation to be enabled on the backend.",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisColorMode": "text",
            "axisLabel": "Requests / second",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 20,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 4,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 200
              }
            ]
          },
          "unit": "reqps"
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "2xx (Success)"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "#73BF69",
                  "mode": "fixed"
                }
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "4xx (Client Error)"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "#FADE2A",
                  "mode": "fixed"
                }
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "5xx (Server Error)"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "#F2495C",
                  "mode": "fixed"
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 9,
        "w": 14,
        "x": 0,
        "y": 25
      },
      "id": 25,
      "options": {
        "legend": {
          "calcs": [
            "mean",
            "max",
            "lastNotNull"
          ],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"2..\"}[5m]))",
          "legendFormat": "2xx (Success)",
          "refId": "A"
        },
        {
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"4..\"}[5m]))",
          "legendFormat": "4xx (Client Error)",
          "refId": "B"
        },
        {
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"5..\"}[5m]))",
          "legendFormat": "5xx (Server Error)",
          "refId": "C"
        }
      ],
      "title": "HTTP Request Rate by Status Class",
      "description": "Traffic segmented by HTTP status class. A spike in total RPS with no 5xx growth = capacity problem. Normal RPS with growing 5xx = code problem.",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisColorMode": "text",
            "axisLabel": "Bytes / second",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 20,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 4,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "Bps"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 10,
        "x": 14,
        "y": 25
      },
      "id": 26,
      "options": {
        "legend": {
          "calcs": [
            "mean",
            "max"
          ],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "sum(rate(fastapi_request_size_bytes_sum[5m])) or vector(0)",
          "legendFormat": "Inbound (req body)",
          "refId": "A"
        },
        {
          "expr": "sum(rate(fastapi_response_size_bytes_sum[5m])) or vector(0)",
          "legendFormat": "Outbound (resp body)",
          "refId": "B"
        }
      ],
      "title": "Bandwidth \u2014 Inbound & Outbound (bytes/sec)",
      "description": "Critical for LLM token streaming workloads. Shows if you are approaching network saturation. Will read 0 if request/response size instrumentation is not enabled on the FastAPI backend.",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 34
      },
      "id": 30,
      "panels": [],
      "title": "\ud83d\udea8  Pillar III \u2014 Errors (The Correctness Pillar)  |  Explicit (5xx) \u00b7 Implicit (wrong body) \u00b7 Policy (SLO breach)",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "max": 1,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.01
              },
              {
                "color": "red",
                "value": 0.05
              }
            ]
          },
          "unit": "percentunit"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 0,
        "y": 35
      },
      "id": 31,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": false,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"5..\"}[5m])) / sum(rate(fastapi_requests_total[5m])) or vector(0)",
          "legendFormat": "Error Rate",
          "refId": "A"
        }
      ],
      "title": "Overall Error Rate %  (Errors / Total Traffic)",
      "description": "The primary SRE correctness signal. Green < 1%, Yellow 1-5%, Red > 5%. This is the 'rate' in your error budget burn.",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.5
              },
              {
                "color": "red",
                "value": 5
              }
            ]
          },
          "unit": "reqps"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 6,
        "y": 35
      },
      "id": 32,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": true,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"5..\"}[5m]))",
          "legendFormat": "5xx/sec",
          "refId": "A"
        }
      ],
      "title": "Explicit Errors \u2014 HTTP 5xx Rate/sec",
      "description": "Server-side failures: connection timeouts, unhandled exceptions, upstream provider failures. These are your loudest, most actionable errors.",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "max": 1,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.05
              },
              {
                "color": "red",
                "value": 0.15
              }
            ]
          },
          "unit": "percentunit"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 12,
        "y": 35
      },
      "id": 33,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": false,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "(sum(rate(fastapi_requests_duration_seconds_count[5m])) - sum(rate(fastapi_requests_duration_seconds_bucket{le=\"2.0\"}[5m]))) / sum(rate(fastapi_requests_duration_seconds_count[5m])) or vector(0)",
          "legendFormat": "SLO Violations",
          "refId": "A"
        }
      ],
      "title": "Policy Violations % \u2014 SLO Breach (> 2s)",
      "description": "Requests that completed successfully (200 OK) but exceeded the 2-second SLO threshold. A 10-second '200 OK' is still a functional failure from the user's perspective.",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 2
              },
              {
                "color": "orange",
                "value": 10
              }
            ]
          },
          "unit": "reqps"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 18,
        "y": 35
      },
      "id": 34,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": true,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"4..\"}[5m]))",
          "legendFormat": "4xx/sec",
          "refId": "A"
        }
      ],
      "title": "Client Errors \u2014 HTTP 4xx Rate/sec",
      "description": "Client-initiated errors (auth failures, bad input, rate limiting). High 4xx rate can indicate abuse, broken clients, or API contract changes.",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisColorMode": "text",
            "axisLabel": "Error Rate",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 25,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 4,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "line",
              "fill": "below"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "transparent",
                "value": null
              },
              {
                "color": "rgba(242, 73, 92, 0.15)",
                "value": 0.05
              }
            ]
          },
          "unit": "percentunit"
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "Explicit (5xx)"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "#F2495C",
                  "mode": "fixed"
                }
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "Policy Breach (> 2s SLO)"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "#FF9830",
                  "mode": "fixed"
                }
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "Client Errors (4xx)"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "#FADE2A",
                  "mode": "fixed"
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 0,
        "y": 39
      },
      "id": 35,
      "options": {
        "legend": {
          "calcs": [
            "mean",
            "max",
            "lastNotNull"
          ],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"5..\"}[5m])) / sum(rate(fastapi_requests_total[5m])) or vector(0)",
          "legendFormat": "Explicit (5xx)",
          "refId": "A"
        },
        {
          "expr": "(sum(rate(fastapi_requests_duration_seconds_count[5m])) - sum(rate(fastapi_requests_duration_seconds_bucket{le=\"2.0\"}[5m]))) / sum(rate(fastapi_requests_duration_seconds_count[5m])) or vector(0)",
          "legendFormat": "Policy Breach (> 2s SLO)",
          "refId": "B"
        },
        {
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"4..\"}[5m])) / sum(rate(fastapi_requests_total[5m])) or vector(0)",
          "legendFormat": "Client Errors (4xx)",
          "refId": "C"
        }
      ],
      "title": "Error Rate by Type \u2014 Explicit \u00b7 Policy Breach \u00b7 Client",
      "description": "Three error categories: Explicit (server failures), Policy (slow 200s violating SLO), Client (bad requests). Separating these avoids alert fatigue \u2014 4xx spikes are usually abuse, not outages.",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisColorMode": "text",
            "axisLabel": "Requests / second",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "bars",
            "fillOpacity": 80,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "linear",
            "lineWidth": 1,
            "pointSize": 4,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "normal"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "reqps"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 12,
        "y": 39
      },
      "id": 36,
      "options": {
        "legend": {
          "calcs": [
            "sum"
          ],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "sum by(status_code) (rate(fastapi_requests_total{status_code=~\"[45]..\"}[5m]))",
          "legendFormat": "HTTP {{status_code}}",
          "refId": "A"
        }
      ],
      "title": "Errors by HTTP Status Code (4xx & 5xx stacked)",
      "description": "Stacked bar breakdown of all error status codes. Useful for identifying if a specific status (e.g. 503, 429) is dominating. Excludes 2xx/3xx success codes.",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 48
      },
      "id": 40,
      "panels": [],
      "title": "\ud83d\udcca  Pillar IV \u2014 Saturation (The Capacity Pillar)  |  Leading indicator \u2014 know before your users feel it",
      "type": "row"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "max": 100,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 70
              },
              {
                "color": "red",
                "value": 90
              }
            ]
          },
          "unit": "percent"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 7,
        "w": 6,
        "x": 0,
        "y": 49
      },
      "id": 41,
      "options": {
        "minVizHeight": 75,
        "minVizWidth": 75,
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showThresholdLabels": false,
        "showThresholdMarkers": true,
        "sizing": "auto"
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "(redis_memory_used_bytes / redis_memory_max_bytes) * 100",
          "legendFormat": "Redis Memory %",
          "refId": "A"
        }
      ],
      "title": "Redis Memory Utilization %",
      "description": "The most constrained shared resource for Gateway Z. At > 90%, Redis starts evicting keys \u2014 this silently degrades rate limiting, session caching, and model catalog caches.",
      "type": "gauge"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "max": 1000,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 500
              },
              {
                "color": "red",
                "value": 800
              }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 7,
        "w": 6,
        "x": 6,
        "y": 49
      },
      "id": 42,
      "options": {
        "minVizHeight": 75,
        "minVizWidth": 75,
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showThresholdLabels": false,
        "showThresholdMarkers": true,
        "sizing": "auto"
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "redis_connected_clients",
          "legendFormat": "Connected Clients",
          "refId": "A"
        }
      ],
      "title": "Redis Connected Clients",
      "description": "Concurrent connections to Redis. Approaching the maxclients limit (default: 10,000 Upstash) means new connections will be refused \u2014 causing cascading failures in rate limiting.",
      "type": "gauge"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 500000000
              },
              {
                "color": "red",
                "value": 1000000000
              }
            ]
          },
          "unit": "bytes"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 7,
        "w": 6,
        "x": 12,
        "y": 49
      },
      "id": 43,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": false,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "process_resident_memory_bytes{job=\"gatewayz_production\"}",
          "legendFormat": "Process RSS",
          "refId": "A"
        }
      ],
      "title": "Backend Process Memory (RSS)",
      "description": "Resident Set Size of the FastAPI process. Sustained growth indicates a memory leak. A sudden spike indicates a large payload or OOM risk. Critical before traffic spikes.",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [
            {
              "options": {
                "0": {
                  "color": "red",
                  "text": "DOWN"
                },
                "1": {
                  "color": "green",
                  "text": "UP"
                }
              },
              "type": "value"
            }
          ],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "red",
                "value": null
              },
              {
                "color": "green",
                "value": 1
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 7,
        "w": 6,
        "x": 18,
        "y": 49
      },
      "id": 44,
      "options": {
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "showPercentChange": false,
        "textMode": "auto",
        "wideLayout": true
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "up{job=\"gatewayz_production\"}",
          "legendFormat": "Backend",
          "refId": "A"
        }
      ],
      "title": "Backend Scrape Target \u2014 UP/DOWN",
      "description": "Prometheus scrape health for the production backend. If this goes DOWN, all metric collection stops and every other panel will go stale \u2014 this is your canary for observability itself.",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisColorMode": "text",
            "axisLabel": "Memory Used",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 20,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 4,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            },
            "thresholdsStyle": {
              "mode": "line"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 0.9
              }
            ]
          },
          "unit": "bytes"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 0,
        "y": 56
      },
      "id": 45,
      "options": {
        "legend": {
          "calcs": [
            "mean",
            "max",
            "lastNotNull"
          ],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "redis_memory_used_bytes",
          "legendFormat": "Used",
          "refId": "A"
        },
        {
          "expr": "redis_memory_max_bytes",
          "legendFormat": "Max Allowed",
          "refId": "B"
        }
      ],
      "title": "Redis Memory \u2014 Used vs Max Capacity",
      "description": "Watch for the 'Used' line approaching 'Max Allowed'. When they converge, Redis begins evicting keys silently, breaking rate limiters and caches without surfacing an explicit error.",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisColorMode": "text",
            "axisLabel": "Count",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 15,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 4,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "short"
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "Connected Clients"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "#5794F2",
                  "mode": "fixed"
                }
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "Blocked Clients"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "#F2495C",
                  "mode": "fixed"
                }
              }
            ]
          }
        ]
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 12,
        "y": 56
      },
      "id": 46,
      "options": {
        "legend": {
          "calcs": [
            "mean",
            "max",
            "lastNotNull"
          ],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "expr": "redis_connected_clients",
          "legendFormat": "Connected Clients",
          "refId": "A"
        },
        {
          "expr": "redis_blocked_clients",
          "legendFormat": "Blocked Clients",
          "refId": "B"
        }
      ],
      "title": "Redis Client Connections \u2014 Active vs Blocked",
      "description": "Blocked clients are waiting on blocking commands (e.g., BLPOP). A growing blocked count indicates work-queue depth is building \u2014 a leading indicator of saturation before users feel it.",
      "type": "timeseries"
    },
    {
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 65
      },
      "id": 50,
      "panels": [],
      "title": "\ud83d\uddfa\ufe0f  Service Graph & Topology \u2014 Upstream vs Downstream Failure Analysis  |  Powered by Tempo metrics-generator \u2192 Mimir",
      "type": "row"
    },
    {
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "gridPos": {
        "h": 6,
        "w": 24,
        "x": 0,
        "y": 66
      },
      "id": 51,
      "options": {
        "code": {
          "language": "plaintext",
          "showLineNumbers": false,
          "showMiniMap": false
        },
        "content": "### Service Graph \u2014 what it shows and why the panels may read \"No data\"\n\nThis section reads from `traces_service_graph_*` metrics that Tempo's `metrics_generator` writes to Mimir. **These metrics only exist when Tempo receives a trace that contains spans from at least two different `service.name` values.** GatewayZ is a single-service gateway \u2014 the AI providers it calls (OpenAI, Anthropic, OpenRouter, etc.) are external HTTP endpoints that do not participate in OTel tracing and do not propagate `traceparent` headers back. Every trace Tempo receives therefore has only one `service.name`, so the service-graphs processor has no edges to draw.\n\n**What would make data appear here:** If the backend adds a child span with `peer.service = \"openai\"` (or the provider name) for each outbound call, Tempo will generate `gatewayz-backend \u2192 openai` edges. That is the accurate framing \u2014 not \"Service A vs Service B\" in a microservices sense, but **\"gateway processing time vs provider inference time\"** on a per-request basis.\n\n**Cross-signal navigation (works today):** Click the blue \u25c6 exemplar dot on any latency graph to jump to the exact Tempo trace. In Loki log panels click **\"View Trace\"** next to any `trace_id` to open the Tempo waterfall. In Tempo, click any span \u2192 **\"Related metrics\"** links to Mimir, **\"Related logs\"** links to Loki.",
        "mode": "markdown"
      },
      "pluginVersion": "11.5.2",
      "title": "",
      "transparent": true,
      "type": "text"
    },
    {
      "datasource": {
        "type": "tempo",
        "uid": "grafana_tempo"
      },
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "gridPos": {
        "h": 14,
        "w": 12,
        "x": 0,
        "y": 70
      },
      "id": 52,
      "options": {},
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "datasource": {
            "type": "tempo",
            "uid": "grafana_tempo"
          },
          "queryType": "serviceMap",
          "refId": "A"
        }
      ],
      "title": "Live Service Dependency Map",
      "description": "Auto-generated from Tempo span data. Node size = request volume. Edge color = error rate (green\u2192yellow\u2192red). Click a node to filter Tempo traces to that service. Requires Tempo metrics_generator service-graphs processor (already enabled).",
      "type": "nodeGraph"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_mimir"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisColorMode": "text",
            "axisLabel": "Requests / second",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 15,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 4,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              }
            ]
          },
          "unit": "reqps"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 7,
        "w": 12,
        "x": 12,
        "y": 70
      },
      "id": 53,
      "options": {
        "legend": {
          "calcs": [
            "mean",
            "max"
          ],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_mimir"
          },
          "expr": "sum by(client, server) (rate(traces_service_graph_request_total[$__rate_interval]))",
          "legendFormat": "{{client}} \u2192 {{server}}",
          "refId": "A"
        }
      ],
      "title": "Service-to-Service Request Rate (RPS)",
      "description": "Traffic volume on each service edge observed by Tempo. A sudden drop to zero on an edge means that dependency is completely unreachable \u2014 a leading indicator of a cascading failure.",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_mimir"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisColorMode": "text",
            "axisLabel": "Error Rate",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 20,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 4,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            }
          },
          "mappings": [],
          "max": 1,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.01
              },
              {
                "color": "red",
                "value": 0.05
              }
            ]
          },
          "unit": "percentunit"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 7,
        "w": 12,
        "x": 12,
        "y": 77
      },
      "id": 54,
      "options": {
        "legend": {
          "calcs": [
            "mean",
            "max"
          ],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_mimir"
          },
          "expr": "sum by(client, server) (rate(traces_service_graph_request_failed_total[$__rate_interval])) / sum by(client, server) (rate(traces_service_graph_request_total[$__rate_interval]))",
          "legendFormat": "{{client}} \u2192 {{server}}",
          "refId": "A"
        }
      ],
      "title": "Service-to-Service Error Rate %",
      "description": "Cross-service error rate per edge. This tells you if a latency spike in the gateway is coming from an upstream AI provider failure (server edge goes red) or from gateway-internal code (client edge stays green).",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_mimir"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "custom": {
            "axisBorderShow": false,
            "axisColorMode": "text",
            "axisLabel": "Latency (seconds)",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "opacity",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "insertNulls": false,
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "pointSize": 4,
            "scaleDistribution": {
              "type": "linear"
            },
            "showPoints": "never",
            "spanNulls": false,
            "stacking": {
              "group": "A",
              "mode": "none"
            }
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 1.0
              },
              {
                "color": "red",
                "value": 3.0
              }
            ]
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 9,
        "w": 24,
        "x": 0,
        "y": 84
      },
      "id": 55,
      "options": {
        "legend": {
          "calcs": [
            "mean",
            "max",
            "lastNotNull"
          ],
          "displayMode": "table",
          "placement": "right",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "pluginVersion": "11.5.2",
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_mimir"
          },
          "expr": "histogram_quantile(0.95, sum by(client, server, le) (rate(traces_service_graph_request_duration_seconds_bucket[$__rate_interval])))",
          "legendFormat": "P95 \u00b7 {{client}} \u2192 {{server}}",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_mimir"
          },
          "expr": "histogram_quantile(0.99, sum by(client, server, le) (rate(traces_service_graph_request_duration_seconds_bucket[$__rate_interval])))",
          "legendFormat": "P99 \u00b7 {{client}} \u2192 {{server}}",
          "refId": "B"
        }
      ],
      "title": "Cross-Service Latency \u2014 P95 & P99 per Edge",
      "description": "P95/P99 latency for every client\u2192server pair in the service graph. Separates upstream provider slowness from gateway processing time \u2014 the key to distinguishing capacity problems from code problems.",
      "type": "timeseries"
    },
    {
      "id": 60,
      "type": "row",
      "title": "\ud83c\udfaf  SLO Compliance & Error Budget  |  99.5% Success Rate \u00b7 Error Budget Burn Rate Tracking",
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 93
      },
      "panels": []
    },
    {
      "id": 61,
      "type": "stat",
      "title": "SLO Compliance \u2014 Success Rate % (window)",
      "description": "% of requests that returned non-5xx. SLO target: 99.5%. Uses Mimir for long-range queries.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_mimir"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 0,
        "y": 94
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "percent",
          "decimals": 3,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "red",
                "value": null
              },
              {
                "color": "orange",
                "value": 99.0
              },
              {
                "color": "green",
                "value": 99.5
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_mimir"
          },
          "expr": "(1 - sum(rate(fastapi_requests_total{status_code=~\"5..\"}[$__range])) / sum(rate(fastapi_requests_total[$__range]))) * 100",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 62,
      "type": "stat",
      "title": "Error Budget Remaining %",
      "description": "How much error budget is left. 0% = SLO breached. 100% = no errors used yet.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_mimir"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 6,
        "y": 94
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "percent",
          "decimals": 1,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "red",
                "value": null
              },
              {
                "color": "orange",
                "value": 10
              },
              {
                "color": "yellow",
                "value": 25
              },
              {
                "color": "green",
                "value": 50
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_mimir"
          },
          "expr": "clamp_min((0.005 - clamp_min(sum(increase(fastapi_requests_total{status_code=~\"5..\"}[$__range])) / sum(increase(fastapi_requests_total[$__range])), 0)) / 0.005 * 100, 0)",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 63,
      "type": "stat",
      "title": "Burn Rate \u2014 1h  (page if > 14.4\u00d7)",
      "description": "Error burn rate relative to SLO error budget. >14.4\u00d7 means you'll exhaust the 30-day budget in ~2h. >6\u00d7 means ~5h.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 12,
        "y": 94
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 2,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "orange",
                "value": 6
              },
              {
                "color": "red",
                "value": 14.4
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"5..\"}[1h])) / sum(rate(fastapi_requests_total[1h])) / 0.005",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 64,
      "type": "stat",
      "title": "Burn Rate \u2014 6h  (page if > 6\u00d7)",
      "description": "Slower burn rate. >6\u00d7 sustained for 6h will exhaust the 30-day budget in ~5 days.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 18,
        "y": 94
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 2,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "orange",
                "value": 3
              },
              {
                "color": "red",
                "value": 6
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"5..\"}[6h])) / sum(rate(fastapi_requests_total[6h])) / 0.005",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 65,
      "type": "timeseries",
      "title": "Error Budget Burn Rate Over Time  (1h \u00b7 6h windows)",
      "description": "Values above the threshold lines indicate fast error budget consumption. Burn Rate 1 = consuming at exactly SLO-defined pace.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 8,
        "w": 24,
        "x": 0,
        "y": 98
      },
      "options": {
        "legend": {
          "calcs": [
            "last",
            "max"
          ],
          "displayMode": "table",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 8,
            "gradientMode": "opacity",
            "showPoints": "never",
            "spanNulls": true
          }
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "Page Threshold (14.4\u00d7)"
            },
            "properties": [
              {
                "id": "custom.lineStyle",
                "value": {
                  "fill": "dash",
                  "dash": [
                    6,
                    4
                  ]
                }
              },
              {
                "id": "color",
                "value": {
                  "fixedColor": "red",
                  "mode": "fixed"
                }
              },
              {
                "id": "custom.lineWidth",
                "value": 1
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "Ticket Threshold (6\u00d7)"
            },
            "properties": [
              {
                "id": "custom.lineStyle",
                "value": {
                  "fill": "dash",
                  "dash": [
                    6,
                    4
                  ]
                }
              },
              {
                "id": "color",
                "value": {
                  "fixedColor": "orange",
                  "mode": "fixed"
                }
              },
              {
                "id": "custom.lineWidth",
                "value": 1
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "Burn Rate 1h"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "red",
                  "mode": "fixed"
                }
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "Burn Rate 6h"
            },
            "properties": [
              {
                "id": "color",
                "value": {
                  "fixedColor": "orange",
                  "mode": "fixed"
                }
              }
            ]
          }
        ]
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"5..\"}[1h])) / sum(rate(fastapi_requests_total[1h])) / 0.005",
          "legendFormat": "Burn Rate 1h",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"5..\"}[6h])) / sum(rate(fastapi_requests_total[6h])) / 0.005",
          "legendFormat": "Burn Rate 6h",
          "refId": "B"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "vector(14.4)",
          "legendFormat": "Page Threshold (14.4\u00d7)",
          "refId": "C"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "vector(6)",
          "legendFormat": "Ticket Threshold (6\u00d7)",
          "refId": "D"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 66,
      "type": "row",
      "title": "\ud83d\udd0d  4xx Error Breakdown  |  Auth Failures \u00b7 Routing \u00b7 Validation \u00b7 Rate Limiting \u00b7 Client Aborts",
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 106
      },
      "panels": []
    },
    {
      "id": 67,
      "type": "stat",
      "title": "Auth Failures \u2014 401 / 403",
      "description": "401 = missing/invalid auth token. 403 = authenticated but unauthorized. Spikes may indicate credential leaks or bad deploys.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 0,
        "y": 107
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "decimals": 3,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.01
              },
              {
                "color": "red",
                "value": 0.1
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"401|403\"}[5m]))",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 68,
      "type": "stat",
      "title": "Not Found \u2014 404",
      "description": "Routing misses. A spike post-deploy indicates contract drift or broken client integrations.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 6,
        "y": 107
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "decimals": 3,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.05
              },
              {
                "color": "orange",
                "value": 0.5
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=\"404\"}[5m]))",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 69,
      "type": "stat",
      "title": "Conflict / Validation \u2014 409 / 422",
      "description": "409=conflict, 422=validation failure. Rising rate may indicate schema drift or bad payload patterns.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 12,
        "y": 107
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "decimals": 3,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.05
              },
              {
                "color": "orange",
                "value": 0.2
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"409|422\"}[5m]))",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 70,
      "type": "stat",
      "title": "Rate Limited \u2014 429",
      "description": "Requests rejected by rate limiter. High rate = abusive clients or traffic spike beyond capacity.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 18,
        "y": 107
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "decimals": 3,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.1
              },
              {
                "color": "red",
                "value": 1.0
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=\"429\"}[5m]))",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 71,
      "type": "timeseries",
      "title": "4xx Error Rate by Code \u2014 Over Time",
      "description": "Each 4xx code tells a different story. Correlate spikes with deploys using the version label.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 9,
        "w": 14,
        "x": 0,
        "y": 111
      },
      "options": {
        "legend": {
          "calcs": [
            "last",
            "max"
          ],
          "displayMode": "table",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 8,
            "gradientMode": "opacity",
            "showPoints": "never",
            "spanNulls": true
          }
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=\"401\"}[5m]))",
          "legendFormat": "401 Unauthorized",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=\"403\"}[5m]))",
          "legendFormat": "403 Forbidden",
          "refId": "B"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=\"404\"}[5m]))",
          "legendFormat": "404 Not Found",
          "refId": "C"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=\"409\"}[5m]))",
          "legendFormat": "409 Conflict",
          "refId": "D"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=\"422\"}[5m]))",
          "legendFormat": "422 Validation",
          "refId": "E"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=\"429\"}[5m]))",
          "legendFormat": "429 Rate Limited",
          "refId": "F"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 72,
      "type": "timeseries",
      "title": "Client Disconnects \u2014 499 (Aborted Requests)",
      "description": "499 = client closed connection before server responded. Rising 499s alongside 5xx suggest cascading slow-response issues. A silent reliability signal \u2014 not counted in 5xx rate.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 9,
        "w": 10,
        "x": 14,
        "y": 111
      },
      "options": {
        "legend": {
          "calcs": [
            "last",
            "max"
          ],
          "displayMode": "table",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 8,
            "gradientMode": "opacity",
            "showPoints": "never",
            "spanNulls": true
          }
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "5xx Rate (context)"
            },
            "properties": [
              {
                "id": "custom.lineStyle",
                "value": {
                  "fill": "dash",
                  "dash": [
                    4,
                    4
                  ]
                }
              },
              {
                "id": "custom.opacity",
                "value": 50
              }
            ]
          }
        ]
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=\"499\"}[5m]))",
          "legendFormat": "499 Client Abort",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=~\"5..\"}[5m]))",
          "legendFormat": "5xx Rate (context)",
          "refId": "B"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 73,
      "type": "row",
      "title": "\u2699\ufe0f  Process Saturation  |  CPU \u00b7 File Descriptors \u00b7 In-Flight Requests \u00b7 Process Uptime",
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 120
      },
      "panels": []
    },
    {
      "id": 74,
      "type": "gauge",
      "title": "CPU Usage % (5m avg)",
      "description": "FastAPI/uvicorn CPU usage. Sustained >80% causes event loop lag and tail latency blowup.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 7,
        "w": 6,
        "x": 0,
        "y": 121
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "showThresholdLabels": false,
        "showThresholdMarkers": true
      },
      "fieldConfig": {
        "defaults": {
          "unit": "percent",
          "decimals": 1,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 50
              },
              {
                "color": "orange",
                "value": 70
              },
              {
                "color": "red",
                "value": 85
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "min": 0,
          "max": 100
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "rate(process_cpu_seconds_total{job=\"gatewayz_production\"}[5m]) * 100",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 75,
      "type": "gauge",
      "title": "In-Flight Requests (Active)",
      "description": "Requests currently being processed. Sustained high values indicate back-pressure or slow providers.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 7,
        "w": 6,
        "x": 6,
        "y": 121
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "showThresholdLabels": false,
        "showThresholdMarkers": true
      },
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 1,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 50
              },
              {
                "color": "orange",
                "value": 100
              },
              {
                "color": "red",
                "value": 200
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "min": 0,
          "max": 300
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(fastapi_requests_in_progress)",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 76,
      "type": "gauge",
      "title": "Open File Descriptors %",
      "description": "File descriptor exhaustion causes 'too many open files' errors and connection failures. >90% = imminent danger.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 7,
        "w": 6,
        "x": 12,
        "y": 121
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "showThresholdLabels": false,
        "showThresholdMarkers": true
      },
      "fieldConfig": {
        "defaults": {
          "unit": "percent",
          "decimals": 1,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 60
              },
              {
                "color": "orange",
                "value": 80
              },
              {
                "color": "red",
                "value": 90
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "min": 0,
          "max": 100
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "process_open_fds{job=\"gatewayz_production\"} / process_max_fds{job=\"gatewayz_production\"} * 100",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 77,
      "type": "stat",
      "title": "Process Uptime (restarts = drop to 0)",
      "description": "Time since last process start. A sudden drop to 0 indicates a crash/restart. Track alongside OOM kills and crash loops.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 7,
        "w": 6,
        "x": 18,
        "y": 121
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "decimals": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "red",
                "value": null
              },
              {
                "color": "orange",
                "value": 60
              },
              {
                "color": "green",
                "value": 300
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "time() - process_start_time_seconds{job=\"gatewayz_production\"}",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 78,
      "type": "timeseries",
      "title": "CPU & Memory Saturation Over Time",
      "description": "CPU throttling and memory pressure both degrade tail latency. Watch for RSS growth (memory leak).",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 0,
        "y": 128
      },
      "options": {
        "legend": {
          "calcs": [
            "last",
            "max"
          ],
          "displayMode": "table",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 8,
            "gradientMode": "opacity",
            "showPoints": "never",
            "spanNulls": true
          }
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "Memory RSS (bytes)"
            },
            "properties": [
              {
                "id": "unit",
                "value": "bytes"
              },
              {
                "id": "custom.axisPlacement",
                "value": "right"
              }
            ]
          },
          {
            "matcher": {
              "id": "byName",
              "options": "CPU % (5m)"
            },
            "properties": [
              {
                "id": "unit",
                "value": "percent"
              }
            ]
          }
        ]
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "rate(process_cpu_seconds_total{job=\"gatewayz_production\"}[5m]) * 100",
          "legendFormat": "CPU % (5m)",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "process_resident_memory_bytes{job=\"gatewayz_production\"}",
          "legendFormat": "Memory RSS (bytes)",
          "refId": "B"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 79,
      "type": "timeseries",
      "title": "In-Flight Requests & File Descriptors Over Time",
      "description": "Correlated view: rising in-flight requests cause rising FD usage (socket connections). If FDs hit max, new connections fail.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 12,
        "y": 128
      },
      "options": {
        "legend": {
          "calcs": [
            "last",
            "max"
          ],
          "displayMode": "table",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 8,
            "gradientMode": "opacity",
            "showPoints": "never",
            "spanNulls": true
          }
        },
        "overrides": [
          {
            "matcher": {
              "id": "byName",
              "options": "Max FDs"
            },
            "properties": [
              {
                "id": "custom.lineStyle",
                "value": {
                  "fill": "dash",
                  "dash": [
                    6,
                    4
                  ]
                }
              },
              {
                "id": "color",
                "value": {
                  "fixedColor": "red",
                  "mode": "fixed"
                }
              },
              {
                "id": "custom.lineWidth",
                "value": 1
              }
            ]
          }
        ]
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(fastapi_requests_in_progress)",
          "legendFormat": "In-Flight Requests",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "process_open_fds{job=\"gatewayz_production\"}",
          "legendFormat": "Open FDs",
          "refId": "B"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "process_max_fds{job=\"gatewayz_production\"}",
          "legendFormat": "Max FDs",
          "refId": "C"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 80,
      "type": "row",
      "title": "\u23f1\ufe0f  Timeouts, Cancellations & Payload Size  |  Silent Reliability Killers",
      "collapsed": false,
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 137
      },
      "panels": []
    },
    {
      "id": 81,
      "type": "stat",
      "title": "Concurrency Gate Rejections/s",
      "description": "Requests rejected by the concurrency gate before they reach FastAPI. These are NOT counted in 5xx rate but ARE reliability failures.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 0,
        "y": 138
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "decimals": 3,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.1
              },
              {
                "color": "red",
                "value": 1.0
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(concurrency_rejected_total[5m]))",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 82,
      "type": "stat",
      "title": "Request Body Size \u2014 P95",
      "description": "P95 request body size. Large payloads silently destroy P99 latency. >1MB warrants investigation.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 6,
        "y": 138
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "bytes",
          "decimals": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 1048576
              },
              {
                "color": "red",
                "value": 10485760
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "histogram_quantile(0.95, sum by (le) (rate(fastapi_request_size_bytes_bucket[5m])))",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 83,
      "type": "stat",
      "title": "Response Body Size \u2014 P95",
      "description": "P95 response body size. Large responses cause TCP back-pressure and client timeout spikes.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 12,
        "y": 138
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "bytes",
          "decimals": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 5242880
              },
              {
                "color": "red",
                "value": 52428800
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "histogram_quantile(0.95, sum by (le) (rate(fastapi_response_size_bytes_bucket[5m])))",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 84,
      "type": "stat",
      "title": "Client Disconnects \u2014 499/s",
      "description": "499 = client closed connection before server responded. Often precedes 5xx spikes. Not in error rate \u2014 invisible without this panel.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 18,
        "y": 138
      },
      "options": {
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto",
        "colorMode": "background",
        "graphMode": "none",
        "justifyMode": "center"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "decimals": 3,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 0.05
              },
              {
                "color": "red",
                "value": 0.5
              }
            ]
          },
          "color": {
            "mode": "thresholds"
          },
          "mappings": []
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(fastapi_requests_total{status_code=\"499\"}[5m]))",
          "instant": true,
          "legendFormat": "__auto",
          "refId": "A"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 85,
      "type": "timeseries",
      "title": "Concurrency Gate Rejections by Reason",
      "description": "Breakdown of WHY requests were rejected. Timeout rejections \u2192 providers too slow. Overload rejections \u2192 need horizontal scaling.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 0,
        "y": 142
      },
      "options": {
        "legend": {
          "calcs": [
            "last",
            "max"
          ],
          "displayMode": "table",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 8,
            "gradientMode": "opacity",
            "showPoints": "never",
            "spanNulls": true
          }
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(concurrency_rejected_total[5m]))",
          "legendFormat": "Rejected (all reasons)",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(concurrency_rejected_total{reason=\"timeout\"}[5m]))",
          "legendFormat": "Rejected \u2014 timeout",
          "refId": "B"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "sum(rate(concurrency_rejected_total{reason=\"overload\"}[5m]))",
          "legendFormat": "Rejected \u2014 overload",
          "refId": "C"
        }
      ],
      "pluginVersion": "11.5.2"
    },
    {
      "id": 86,
      "type": "timeseries",
      "title": "Request & Response Payload Size Distribution",
      "description": "P99 request size spikes before P99 latency spikes \u2014 this is a leading indicator. Large response P95 \u2192 TCP back-pressure.",
      "datasource": {
        "type": "prometheus",
        "uid": "grafana_prometheus"
      },
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 12,
        "y": 142
      },
      "options": {
        "legend": {
          "calcs": [
            "last",
            "max"
          ],
          "displayMode": "table",
          "placement": "bottom",
          "showLegend": true
        },
        "tooltip": {
          "mode": "multi",
          "sort": "desc"
        }
      },
      "fieldConfig": {
        "defaults": {
          "unit": "bytes",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "lineWidth": 2,
            "fillOpacity": 8,
            "gradientMode": "opacity",
            "showPoints": "never",
            "spanNulls": true
          }
        },
        "overrides": []
      },
      "targets": [
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "histogram_quantile(0.50, sum by (le) (rate(fastapi_request_size_bytes_bucket[5m])))",
          "legendFormat": "Request P50",
          "refId": "A"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "histogram_quantile(0.95, sum by (le) (rate(fastapi_request_size_bytes_bucket[5m])))",
          "legendFormat": "Request P95",
          "refId": "B"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "histogram_quantile(0.99, sum by (le) (rate(fastapi_request_size_bytes_bucket[5m])))",
          "legendFormat": "Request P99",
          "refId": "C"
        },
        {
          "datasource": {
            "type": "prometheus",
            "uid": "grafana_prometheus"
          },
          "expr": "histogram_quantile(0.95, sum by (le) (rate(fastapi_response_size_bytes_bucket[5m])))",
          "legendFormat": "Response P95",
          "refId": "D"
        }
      ],
      "pluginVersion": "11.5.2"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 41,
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "All",
          "value": "$__all"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "grafana_mimir"
        },
        "definition": "label_values(traces_service_graph_request_total, server)",
        "hide": 0,
        "includeAll": true,
        "multi": true,
        "name": "service",
        "options": [],
        "query": {
          "query": "label_values(traces_service_graph_request_total, server)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 2,
        "regex": "",
        "sort": 1,
        "label": "Service",
        "type": "query"
      }
    ]
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "browser",
  "title": "GatewayZ \u2014 Four Golden Signals (SRE)",
  "uid": "gatewayz-four-golden-signals",
  "version": 1
}
