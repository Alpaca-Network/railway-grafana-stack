# Configuration file version
# See here fore more information on configuration:
# https://grafana.com/docs/grafana/latest/administration/provisioning/#example-data-source-configuration-file
apiVersion: 1

# Mark provisioned data sources for deletion if they are no longer in a provisioning file.
prune: false

# List of data sources to insert/update depending on what's available.
datasources:
  - name: Loki
    type: loki
    access: direct
    orgId: 1
    uid: grafana_loki
    url: ${LOKI_INTERNAL_URL}
    user:
    database:
    basicAuth:
    basicAuthUser:
    withCredentials:
    isDefault: true
    jsonData:
      derivedFields:
        - datasourceUid: grafana_tempo
          matcherRegex: "trace_id=(\\w+)"
          name: TraceID
          url: '$${__value.raw}'
  - name: Prometheus
    type: prometheus
    access: proxy
    orgId: 1
    uid: grafana_prometheus
    url: ${PROMETHEUS_INTERNAL_URL}
    user:
    database:
    basicAuth:
    basicAuthUser:
    withCredentials:
    isDefault: false
    jsonData:
      exemplarTraceIdDestinations:
        - datasourceUid: grafana_tempo
          name: trace_id
  - name: Tempo
    type: tempo
    access: proxy
    orgId: 1
    uid: grafana_tempo
    # Tempo URL - Internal DNS for same-project access
    # Grafana and Tempo are in the same Railway project (railway-grafana-stack)
    # Port 3200 is Tempo's query API (not 4318 which is for ingestion)
    # NOTE: TEMPO_INTERNAL_URL is set in Dockerfile to http://tempo.railway.internal:3200
    url: ${TEMPO_INTERNAL_URL}
    user:
    database:
    basicAuth:
    basicAuthUser:
    withCredentials:
    isDefault: false
    jsonData:
      tracesToLogsV2:
        datasourceUid: 'grafana_loki'
        spanStartTimeShift: '-1h'
        spanEndTimeShift: '1h'
        tags: ['service_name', 'compose_service']
        filterByTraceID: true
        filterBySpanID: false
      # IMPORTANT: span metrics (traces_spanmetrics_*) and service-graph metrics
      # (traces_service_graph_*) are generated by Tempo's metrics_generator and
      # remote-written DIRECTLY to Mimir — they are NOT scraped by Prometheus.
      # Both datasourceUids below MUST point to grafana_mimir, not grafana_prometheus.
      tracesToMetrics:
        datasourceUid: 'grafana_mimir'
        spanStartTimeShift: '-5m'
        spanEndTimeShift: '5m'
        tags:
          - key: 'service.name'
            value: 'service_name'
      serviceMap:
        datasourceUid: 'grafana_mimir'
      nodeGraph:
        enabled: true
      search:
        hide: false
      lokiSearch:
        datasourceUid: 'grafana_loki'
      # Trace → Profile: clicking a slow span opens the Pyroscope flamegraph
      # recorded during that exact time window.
      # Requires PYROSCOPE_SERVER_ADDRESS to be set on the Grafana service.
      tracesToProfiles:
        datasourceUid: 'grafana_pyroscope'
        profileTypeId: 'process_cpu:cpu:nanoseconds:cpu:nanoseconds'
        tags:
          - key: 'service.name'
            value: 'service_name'
  - name: Sentry
    type: grafana-sentry-datasource
    access: proxy
    orgId: 1
    uid: grafana_sentry
    url: ${SENTRY_INTERNAL_URL}
    user:
    database:
    basicAuth:
    basicAuthUser:
    withCredentials:
    isDefault: false
    jsonData:
      authTokenName: Authorization
    secureJsonData:
      authToken: ${SENTRY_AUTH_TOKEN:-}
  - name: JSON API
    type: grafana-simple-json-datasource
    access: proxy
    orgId: 1
    uid: grafana_json_api
    url: ${API_BASE_URL:-https://api.gatewayz.ai}/prometheus/datasource
    user:
    database:
    basicAuth:
    basicAuthUser:
    withCredentials:
    isDefault: false

  # Mimir - Long-term metrics storage (Prometheus-compatible)
  # Use this datasource for:
  # - Historical queries (longer than Prometheus retention)
  # - Consistent query results across page refreshes
  # - Aggregated metrics from multiple Prometheus instances
  # NOTE: MIMIR_INTERNAL_URL is set in Dockerfile to http://mimir.railway.internal:9009
  - name: Mimir
    type: prometheus
    access: proxy
    orgId: 1
    uid: grafana_mimir
    url: ${MIMIR_INTERNAL_URL}/prometheus
    user:
    database:
    basicAuth:
    basicAuthUser:
    withCredentials:
    isDefault: false
    jsonData:
      httpMethod: POST
      manageAlerts: false
      prometheusType: Mimir
      prometheusVersion: 2.11.0
      timeout: 60
      # REQUIRED: X-Scope-OrgID header for Mimir tenant identification
      # Even with multitenancy_enabled: false, Mimir requires this header
      # "anonymous" is the default tenant used when multi-tenancy is disabled
      httpHeaderName1: X-Scope-OrgID
      exemplarTraceIdDestinations:
        - datasourceUid: grafana_tempo
          name: trace_id   # underscore — must match OTel convention and backend emission
    secureJsonData:
      httpHeaderValue1: anonymous

  # Pyroscope - Continuous profiling (Grafana Cloud hosted)
  # The backend pushes CPU/memory flamegraph samples to Grafana Cloud.
  # This datasource reads them back so Grafana can display flamegraphs and
  # enable Trace→Profile navigation from Tempo spans.
  #
  # Required env vars on the Grafana Railway service:
  #   PYROSCOPE_SERVER_ADDRESS  e.g. https://profiles-prod-006.grafana.net
  #   PYROSCOPE_AUTH_USER       Grafana Cloud numeric instance ID
  #   PYROSCOPE_AUTH_PASSWORD   Grafana Cloud API token (profiles:read scope)
  #
  # Until these are set the datasource will show a connection error — that is
  # expected and does not affect any other datasource.
  - name: Pyroscope
    type: grafana-pyroscope-datasource
    access: proxy
    orgId: 1
    uid: grafana_pyroscope
    url: ${PYROSCOPE_SERVER_ADDRESS:-}
    isDefault: false
    jsonData:
      httpMethod: GET
    secureJsonData:
      basicAuthUser: ${PYROSCOPE_AUTH_USER:-}
      basicAuthPassword: ${PYROSCOPE_AUTH_PASSWORD:-}
