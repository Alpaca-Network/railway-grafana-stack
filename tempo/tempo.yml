# Tempo 2.6.1 - Transparent Telemetry Ingestion Configuration
# Purpose: Ingest OTLP traces and automatically generate metrics for AI/ML workloads
# Documentation: /docs/architecture/TRANSPARENT_TELEMETRY_INGESTION.md
# Updated: 2026-02-03 - Refactored for transparency and semantic conventions

stream_over_http_enabled: true

server:
  http_listen_port: 3200
  grpc_listen_port: 9095
  http_listen_address: "0.0.0.0"
  grpc_listen_address: "0.0.0.0"
  log_level: info

# ============================================================
# OTLP Receivers - Trace Ingestion Endpoints
# ============================================================
# Receives traces from backend via OpenTelemetry OTLP protocol
# - gRPC endpoint: 0.0.0.0:4317 (binary protocol, lower latency)
# - HTTP endpoint: 0.0.0.0:4318 (JSON/protobuf, easier debugging)
# Backend should use: http://tempo.railway.internal:4318/v1/traces
distributor:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: "0.0.0.0:4317"
        http:
          endpoint: "0.0.0.0:4318"
  log_received_spans:
    enabled: false  # Set to true for debugging trace ingestion
    include_all_attributes: false

# ============================================================
# Ingester - Trace Storage
# ============================================================
# Temporarily stores traces before writing to long-term storage
ingester:
  # Shorter block duration for faster trace visibility
  max_block_duration: 1m
  trace_idle_period: 5s
  flush_check_period: 5s
  # Complete blocks faster for search availability
  complete_block_timeout: 30s

# ============================================================
# Metrics Generator - Automatic Span-to-Metrics Conversion
# ============================================================
# Extracts metrics from trace spans for model popularity, latency, and errors
# Generated metrics: traces_spanmetrics_calls_total, traces_spanmetrics_duration_seconds
# Remote writes to Mimir for long-term storage and querying
metrics_generator:
  # Ring configuration for metrics generator (required for Tempo 2.6.1)
  ring:
    kvstore:
      store: inmemory
  registry:
    external_labels:
      source: tempo
      cluster: gatewayz
      environment: production
    stale_duration: 15m
  storage:
    path: /var/tempo/generator/wal
    remote_write:
      # MIMIR_REMOTE_WRITE_URL is substituted by entrypoint.sh
      # Railway: http://mimir.railway.internal:9009/api/v1/push
      # Local: http://mimir:9009/api/v1/push
      - url: MIMIR_REMOTE_WRITE_URL
        send_exemplars: true  # Links metrics back to traces
        queue_config:
          capacity: 10000
          max_shards: 20
          batch_send_deadline: 5s
    remote_write_flush_deadline: 1m
  traces_storage:
    path: /var/tempo/generator/traces
  processor:
    # --------------------------------------------------------
    # Span Metrics Processor - Extract Dimensions from Traces
    # --------------------------------------------------------
    # Converts trace spans into Prometheus metrics with labels
    # Each unique combination of dimensions creates a new time series
    span_metrics:
      # ===== OpenTelemetry Semantic Convention Dimensions =====
      # Standard attributes following OpenTelemetry Gen AI conventions
      # Docs: https://opentelemetry.io/docs/specs/semconv/gen-ai/
      dimensions:
        # Core service identification
        - service.name                    # Service identifier (e.g., "gatewayz-api")
        - span.name                       # Operation name (auto-captured)
        - span.kind                       # Span type: CLIENT, SERVER, etc. (auto-captured)
        - status.code                     # Span status: OK, ERROR (auto-captured)

        # OpenTelemetry Gen AI attributes (REQUIRED)
        - gen_ai.system                   # AI provider: openai, anthropic, vertex_ai
        - gen_ai.request.model            # Requested model name
        - gen_ai.response.model           # Actual model used (may differ)
        - gen_ai.operation.name           # Operation: chat, completion, embedding

        # HTTP attributes for error tracking
        - http.response.status_code       # HTTP status: 200, 429, 500, etc.

        # Server attributes for provider identification
        - server.address                  # Provider API endpoint

        # ===== GatewayZ-Specific Dimensions =====
        # Custom attributes for GatewayZ business logic
        - gatewayz.provider.name          # GatewayZ provider: openrouter, cerebras
        - gatewayz.customer.id            # Customer/tenant identifier
        - gatewayz.request.type           # Detailed request type: chat_completion, etc.

        # Legacy compatibility (DEPRECATED - use gen_ai.* instead)
        - ai.provider                     # Legacy: map to gatewayz.provider.name
        - ai.model_id                     # Legacy: map to gen_ai.request.model

      # Histogram configuration for latency percentiles (P50, P95, P99)
      # Buckets optimized for AI/ML latency ranges (10ms to 60s)
      histogram_buckets: [0.01, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30, 60]

      # Enable target_info metric for metadata queries
      enable_target_info: true

      # Dimensions cache to improve performance with high cardinality
      dimensions_cache_size: 5000

      # Filter spans before processing (optional)
      # filter_policies:
      #   - include:
      #       match_type: strict
      #       attributes:
      #         - key: gen_ai.operation.name
      #           value: chat

    # --------------------------------------------------------
    # Service Graphs Processor - Dependency Mapping
    # --------------------------------------------------------
    # Creates service-to-service dependency metrics
    service_graphs:
      dimensions:
        - service.name
        - gen_ai.system
        - gatewayz.provider.name
      max_items: 10000
      wait: 10s

# Overrides for high-cardinality attributes
overrides:
  defaults:
    metrics_generator:
      processors: [span-metrics, service-graphs]
      # Enable metrics generation for all traces
      generate_native_histograms: both

compactor:
  compaction:
    block_retention: 48h

# Querier configuration for Tempo 2.6.1
querier:
  max_concurrent_queries: 20
  frontend_worker:
    frontend_address: ""

# Query Frontend configuration for TraceQL
query_frontend:
  search:
    duration_slo: 5s
    concurrent_jobs: 2000
  trace_by_id:
    duration_slo: 5s

storage:
  trace:
    backend: local
    local:
      path: /var/tempo/traces
    wal:
      path: /var/tempo/wal
    pool:
      max_workers: 100
      queue_depth: 10000
    # Block configuration for search
    block:
      # vParquet4 enables efficient TraceQL queries
      version: vParquet4
