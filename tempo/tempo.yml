# Tempo 2.6.1 - Configuration optimized for Railway
# Updated: OpenLLMetry/Traceloop integration with span metrics
stream_over_http_enabled: true

server:
  http_listen_port: 3200
  grpc_listen_port: 9095
  http_listen_address: "0.0.0.0"
  grpc_listen_address: "0.0.0.0"

# OTLP receivers for trace ingestion
distributor:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: "0.0.0.0:4317"
        http:
          endpoint: "0.0.0.0:4318"

ingester:
  max_block_duration: 5m
  trace_idle_period: 10s
  flush_check_period: 10s

# Metrics Generator - Creates span metrics for Prometheus
# This enables the traces_spanmetrics_* metrics for "most popular models" queries
# Prometheus scrapes these metrics from Tempo's /metrics endpoint
metrics_generator:
  registry:
    external_labels:
      source: tempo
      cluster: gatewayz
  storage:
    path: /var/tempo/generator/wal
  processor:
    span_metrics:
      # Include LLM-specific dimensions for model popularity tracking
      dimensions:
        - service.name
        - gen_ai.request.model
        - gen_ai.system
        - ai.provider
        - ai.model_id
        - customer.id
        - http.status_code
      # Enable histogram for latency analysis
      enable_target_info: true
      histogram_buckets: [0.01, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]
    # Service graphs for dependency mapping
    service_graphs:
      dimensions:
        - service.name
        - gen_ai.system

# Overrides for high-cardinality attributes
overrides:
  defaults:
    metrics_generator:
      processors: [span-metrics, service-graphs]
      # Enable metrics generation for all traces
      generate_native_histograms: both

compactor:
  compaction:
    block_retention: 48h

# Querier configuration - enables searching recent traces in ingester/WAL
querier:
  # Search the ingester for recent traces (critical for real-time visibility!)
  search:
    # Search ingester for traces not yet flushed to blocks
    query_ingesters: true
    # External hedge requests for faster responses
    external_hedge_requests_at: 5s
    external_hedge_requests_up_to: 3
  # Also query ingester for trace by ID lookups
  trace_by_id:
    query_ingesters: true

# Query Frontend configuration for TraceQL
query_frontend:
  search:
    # Duration to wait for a block to be searched
    duration_slo: 5s
    # Number of concurrent jobs
    concurrent_jobs: 2000
    # Search ingester for recent data
    query_ingesters: true
  trace_by_id:
    duration_slo: 5s
    # Include ingester in trace lookups
    query_ingesters: true

storage:
  trace:
    backend: local
    local:
      path: /var/tempo/traces
    wal:
      path: /var/tempo/wal
    pool:
      max_workers: 100
      queue_depth: 10000
    # Block configuration for search
    block:
      # vParquet4 enables efficient TraceQL queries
      version: vParquet4
