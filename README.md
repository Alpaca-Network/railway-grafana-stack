# GatewayZ Observability Stack

**Production-ready observability platform for GatewayZ AI Backend** - Centralized metrics, logs, traces, and visualization with horizontal scaling via Grafana Mimir.

[![Railway Deploy](https://railway.app/button.svg)](https://railway.app)

---

## ğŸš€ Quick Start

### Production Access
- **Grafana Dashboard:** [https://logs.gatewayz.ai](https://logs.gatewayz.ai)

### Local Development (Docker Compose)

```bash
# 1. Clone and navigate to the stack
git clone <repo-url>
cd railway-grafana-stack

# 2. Configure backend metrics scraping (REQUIRED for data to show)
export FASTAPI_TARGET="host.docker.internal:8000"  # If backend runs on host
# OR
export FASTAPI_TARGET="gatewayz-backend:8000"       # If backend is in Docker network

# 3. Start all services
docker compose up --build

# 4. Access services
open http://localhost:3000  # Grafana (admin/yourpassword123)
open http://localhost:9090  # Prometheus
open http://localhost:9009  # Mimir
```

**ğŸ“– Documentation:**
- **[Complete Documentation Index](docs/docs-index.md)** - Start here for all guides and references
- Quick Links:
  - **[Cheatsheet](docs/cheatsheet.md)** - Common commands and queries
  - **[Troubleshooting](docs/troubleshooting/REMOTE_WRITE_DEBUG.md)** - Fix common issues
  - **[Architecture](docs/architecture/MIMIR.md)** - System design and components

---

## ğŸ“Š Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GatewayZ Backend API                         â”‚
â”‚  (FastAPI: api.gatewayz.ai)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚              â”‚
  Metrics (Pull)  Logs (Push)   Traces (Push)
   /metrics      :3100/loki    :4317/:4318
        â”‚             â”‚              â”‚
  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
  â”‚Prometheus â”‚ â”‚   Loki    â”‚ â”‚   Tempo     â”‚
  â”‚  :9090    â”‚ â”‚  :3100    â”‚ â”‚:3200/:4317/ â”‚
  â”‚           â”‚ â”‚           â”‚ â”‚    :4318    â”‚
  â”‚ Scrapes   â”‚ â”‚Log Storageâ”‚ â”‚Trace Storageâ”‚
  â”‚every 15-30sâ”‚ â”‚30d Retain â”‚ â”‚Span Metrics â”‚
  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚              â”‚
        â”‚Remote Write â”‚              â”‚
        â†“             â”‚              â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚              â”‚
  â”‚    Mimir     â”‚   â”‚              â”‚
  â”‚   :9009      â”‚â—„â”€â”€â”˜              â”‚
  â”‚              â”‚                  â”‚
  â”‚Horizontal    â”‚                  â”‚
  â”‚Scaling       â”‚                  â”‚
  â”‚30d Retention â”‚                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
         â”‚                          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
             â”‚   Grafana   â”‚
             â”‚    :3000    â”‚
             â”‚             â”‚
             â”‚4 Datasourcesâ”‚ â† Prometheus, Mimir, Loki, Tempo
             â”‚5 Folders    â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

| Service | Port | Purpose | Status |
|---------|------|---------|--------|
| **Grafana 11.5.2** | 3000 | Visualization & dashboards | âœ… 5 dashboard folders |
| **Prometheus 3.2.1** | 9090 | Metrics collection + alerting | âœ… 6 scrape jobs |
| **Mimir 2.11.0** | 9009, 9095 | Long-term metrics storage | âœ… 30-day retention |
| **Loki 3.4** | 3100 | Log aggregation | âœ… 30-day retention |
| **Tempo** | 3200, 4317, 4318 | Distributed tracing | âœ… OTLP endpoints |
| **Redis Exporter** | 9121 | Redis metrics | âœ… Integrated |

---

## ğŸ¯ Dashboard Folders

All dashboards use **real API endpoints** with live data from Prometheus/Mimir - no mock data.

| Folder | Purpose | Key Metrics | Status |
|--------|---------|-------------|--------|
| **Model Performance** | AI model metrics | Request rates, latency, token usage, error rates | âœ… Ready |
| **Loki** | Log aggregation | Log search, streaming, volume by level/service | âœ… Ready |
| **Prometheus** | Short-term metrics | Scrape targets, query stats, self-monitoring | âœ… Ready |
| **Tempo** | Distributed tracing | Service graph, span metrics, trace search | âœ… Ready |
| **Mimir** | Long-term metrics | Historical queries, retention stats | âœ… Ready |

### Dashboard Features

#### Model Performance
- **AI Provider Metrics**: Request rates by provider/model
- **Latency Analysis**: P50/P95/P99 percentiles
- **Token Usage**: Input/output token tracking
- **Error Rates**: By provider, model, and error type

#### Loki Logs Dashboard
- **Pure log data** from Loki datasource
- **Log Search**: Real-time filtering and search
- **Log Volume**: Count by level, service, severity

#### Tempo Traces Dashboard
- **Pure trace data** from Tempo datasource
- **Service Graph**: Distributed tracing visualization
- **Span Metrics**: Request duration, error rates by service

#### Mimir Long-term Storage
- **Historical Queries**: 30-day retention for trend analysis
- **Consistent Results**: No data loss on Prometheus restarts

---

## âš™ï¸ Configuration

### Prometheus Scrape Jobs

**File:** `prometheus/prometheus.yml`

| Job Name | Target | Interval | Purpose |
|----------|--------|----------|---------|
| `prometheus` | localhost:9090 | 15s | Self-monitoring |
| `gatewayz_production` | `${FASTAPI_TARGET}` | 15s | **Production API metrics** |
| `redis_exporter` | redis-exporter:9121 | 30s | Redis metrics |
| `gatewayz_data_metrics_production` | `${FASTAPI_TARGET}` | 30s | Provider health, circuit breakers |
| `mimir` | mimir:9009 | 30s | Mimir self-monitoring |

#### âš ï¸ **IMPORTANT: `FASTAPI_TARGET` Configuration**

The `${FASTAPI_TARGET}` placeholder **MUST be set** for local development:

```bash
# For backend on host machine (most common)
export FASTAPI_TARGET="host.docker.internal:8000"

# For backend in same Docker network
export FASTAPI_TARGET="gatewayz-backend:8000"

# Verify Prometheus is scraping
curl http://localhost:9090/api/v1/targets
```

**Without this variable, the Backend Services dashboard will show no API data.**

### Grafana Datasources

**Directory:** `grafana/datasources/datasources.yml`

| Datasource | UID | Type | URL | Purpose |
|------------|-----|------|-----|---------|
| **Prometheus** | `grafana_prometheus` | prometheus | `${PROMETHEUS_INTERNAL_URL}` | Short-term metrics |
| **Mimir** | `grafana_mimir` | prometheus | `${MIMIR_INTERNAL_URL}/prometheus` | Long-term metrics |
| **Loki** | `grafana_loki` | loki | `${LOKI_URL}` | Logs |
| **Tempo** | `grafana_tempo` | tempo | `${TEMPO_INTERNAL_URL}` | Traces |

### Data Retention

| Service | Retention | Compaction | Notes |
|---------|-----------|------------|-------|
| **Prometheus** | 15 days | N/A | Short-term, remote writes to Mimir |
| **Mimir** | 30 days | Every 2h | Horizontal scaling, HA-ready |
| **Loki** | 30 days | Every 10m | TSDB index, filesystem storage |
| **Tempo** | 7 days | 5m blocks | Local filesystem |

---

## ğŸ”Œ Backend Integration

### 1. Expose Metrics Endpoint

**Python (FastAPI):**
```python
from prometheus_client import Counter, Histogram, make_asgi_app
from fastapi import FastAPI

app = FastAPI()

# Mount Prometheus metrics endpoint
metrics_app = make_asgi_app()
app.mount("/metrics", metrics_app)

# Define custom metrics
request_counter = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status_code', 'env']
)

latency_histogram = Histogram(
    'http_request_duration_seconds',
    'HTTP request latency',
    ['method', 'endpoint', 'env']
)

# Use in your routes
@app.get("/v1/models")
async def list_models():
    request_counter.labels(
        method="GET",
        endpoint="/v1/models",
        status_code="200",
        env="production"
    ).inc()
    return {"models": [...]}
```

### 2. Send Logs to Loki

**Python with python-logging-loki:**
```python
import logging
from logging_loki import LokiHandler

loki_handler = LokiHandler(
    url="http://loki:3100/loki/api/v1/push",
    tags={"app": "gatewayz", "env": "production"},
    version="1"
)

logger = logging.getLogger("gatewayz")
logger.addHandler(loki_handler)
logger.setLevel(logging.INFO)

# Use structured logging
logger.info("Request processed", extra={
    "user_id": "123",
    "duration_ms": 45,
    "model": "gpt-4"
})
```

### 3. Send Traces to Tempo

**Python with OpenTelemetry:**
```python
from opentelemetry import trace
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

# Configure Tempo exporter
otlp_exporter = OTLPSpanExporter(
    endpoint="http://tempo:4318/v1/traces"
)

# Setup tracing
provider = TracerProvider()
provider.add_span_processor(BatchSpanProcessor(otlp_exporter))
trace.set_tracer_provider(provider)

tracer = trace.get_tracer(__name__)

# Instrument your code
with tracer.start_as_current_span("model_inference") as span:
    span.set_attribute("model", "gpt-4")
    span.set_attribute("provider", "openai")
    result = await call_model_api()
```

**ğŸ“– Complete Integration Guide:** [docs/backend/BACKEND_METRICS_REQUIREMENTS.md](docs/backend/BACKEND_METRICS_REQUIREMENTS.md)

---

## ğŸ”§ Troubleshooting

### Issue: Backend Services Dashboard Shows "No Data"

**Symptom:** All Redis and API panels show "No data"

**Root Cause:** `FASTAPI_TARGET` environment variable not set for local builds

**Solution:**
```bash
# Set the environment variable
export FASTAPI_TARGET="host.docker.internal:8000"

# Restart Prometheus
docker compose restart prometheus

# Verify targets are UP
open http://localhost:9090/targets
```

### Issue: Loki Dashboard Shows "Bad Request"

**Cause:** Query syntax issues or no logs ingested

**Fix:**
1. Verify Loki is receiving logs:
   ```bash
   curl http://localhost:3100/metrics | grep loki_distributor_lines_received_total
   ```
2. Test log ingestion:
   ```bash
   curl -X POST http://localhost:3100/loki/api/v1/push \
     -H "Content-Type: application/json" \
     -d '{"streams":[{"stream":{"app":"test"},"values":[["'$(date +%s%N)'","test message"]]}]}'
   ```
3. Check query syntax in dashboard (LogQL, not PromQL)

**ğŸ“– More Solutions:** [docs/troubleshooting/](docs/troubleshooting/)

### Issue: Grafana Datasource Connection Failed

**Cause:** Datasource UID mismatch or incorrect URLs

**Fix:**
1. Check datasource health:
   ```bash
   # Prometheus
   curl http://localhost:9090/-/healthy
   
   # Mimir
   curl http://localhost:9009/ready
   
   # Loki
   curl http://localhost:3100/ready
   
   # Tempo
   curl http://localhost:3200/ready
   ```

2. Verify datasource UIDs in Grafana:
   - Prometheus: `grafana_prometheus`
   - Mimir: `grafana_mimir`
   - Loki: `grafana_loki`
   - Tempo: `grafana_tempo`

3. Check environment variables in `docker-compose.yml`

### Issue: Mimir Not Receiving Data from Prometheus

**Symptom:** Prometheus is scraping metrics but Mimir shows no data, or Grafana's Mimir datasource returns empty results.

**Root Cause:** Missing `X-Scope-OrgID` header in Prometheus remote_write or Grafana datasource configuration.

**Why This Happens:** Even with `multitenancy_enabled: false` in Mimir, both writes (from Prometheus) and reads (from Grafana) require the `X-Scope-OrgID` header. When multi-tenancy is disabled, Mimir uses `anonymous` as the default tenant.

**Solution:**

1. **Verify Prometheus remote_write has the header** (`prometheus/prometheus.yml`):
   ```yaml
   remote_write:
     - url: http://mimir:9009/api/v1/push
       headers:
         X-Scope-OrgID: anonymous
   ```

2. **Verify Grafana Mimir datasource has the header** (`grafana/datasources/datasources.yml`):
   ```yaml
   - name: Mimir
     type: prometheus
     url: ${MIMIR_INTERNAL_URL}/prometheus
     jsonData:
       httpHeaderName1: X-Scope-OrgID
     secureJsonData:
       httpHeaderValue1: anonymous
   ```

3. **Restart services after configuration changes:**
   ```bash
   docker compose restart prometheus grafana
   ```

4. **Verify Mimir is receiving data:**
   ```bash
   # Check Mimir ingester status
   curl http://localhost:9009/ingester/ring

   # Check remote write metrics in Prometheus
   curl http://localhost:9090/api/v1/query?query=prometheus_remote_storage_samples_total

   # Test Mimir query directly
   curl -H "X-Scope-OrgID: anonymous" "http://localhost:9009/prometheus/api/v1/query?query=up"
   ```

**ğŸ“– More Solutions:** [docs/troubleshooting/REMOTE_WRITE_DEBUG.md](docs/troubleshooting/REMOTE_WRITE_DEBUG.md)

---

## âœ¨ Key Features

### ğŸš€ Horizontal Scaling with Mimir
- Long-term metrics storage with 30-day retention.
- Horizontally scalable architecture.
- Remote write from Prometheus.

### ğŸ“Š Golden Signals Monitoring
- **Latency**: P50/P95/P99 percentiles + trends.
- **Traffic**: Request volume and rates.
- **Errors**: Error rate gauge + trends.
- **Saturation**: CPU/Memory/Redis utilization.

### ğŸ” Specialized Dashboards
- **Executive Overview**: High-level KPIs and alerts.
- **Backend Services**: Redis cache hit rates, API performance.
- **Loki Logs**: Deep log search without metrics noise.
- **Tempo Traces**: Distributed tracing and service graphs.

### ğŸ›¡ï¸ Production Grade
- **Alerting**: Email notifications for health scores and SLO breaches.
- **Testing**: Comprehensive integration test suite (90+ tests).
- **Security**: No hardcoded credentials; fully environment-variable driven.

---

## ğŸ“Š Mimir Long-term Storage Setup

Mimir provides **30-day metric retention** with horizontal scaling. This is critical for:
- Historical trend analysis
- Consistent query results across page refreshes
- No data loss on Prometheus restarts

### How Prometheus â†’ Mimir Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    remote_write     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prometheus â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚    Mimir    â”‚
â”‚   :9090    â”‚   /api/v1/push      â”‚   :9009     â”‚
â”‚            â”‚   X-Scope-OrgID:    â”‚             â”‚
â”‚  (15d)     â”‚   anonymous         â”‚  (30d)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                   â”‚
      â”‚ scrapes                           â”‚ stores
      â–¼                                   â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Backend  â”‚                     â”‚ /data/mimir/ â”‚
 â”‚ /metrics â”‚                     â”‚   blocks/    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚   tsdb/      â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Verifying Mimir is Working

```bash
# 1. Check Mimir is ready
curl http://localhost:9009/ready
# Expected: "ready"

# 2. Check Mimir ingester ring (must show ACTIVE)
curl http://localhost:9009/ingester/ring | jq '.shards[].state'
# Expected: "ACTIVE"

# 3. Check Prometheus remote_write metrics
curl -s http://localhost:9090/api/v1/query?query=prometheus_remote_storage_samples_total | jq '.data.result[].value[1]'
# Expected: increasing number (samples sent)

# 4. Check for remote_write failures
curl -s http://localhost:9090/api/v1/query?query=prometheus_remote_storage_samples_failed_total | jq '.data.result[].value[1]'
# Expected: 0 or very low

# 5. Query Mimir directly
curl -H "X-Scope-OrgID: anonymous" \
  "http://localhost:9009/prometheus/api/v1/query?query=up"
# Expected: JSON with metric data

# 6. Check Mimir logs for write activity
docker compose logs mimir 2>&1 | grep -i "push" | tail -5
```

### Key Configuration Files

| File | Purpose |
|------|---------|
| `prometheus/prometheus.yml` | `remote_write` config with `X-Scope-OrgID: anonymous` header |
| `mimir/mimir.yml` | Local development config (30d retention) |
| `mimir/mimir-railway.yml` | Railway production config |
| `grafana/datasources/datasources.yml` | Mimir datasource with `X-Scope-OrgID` header |

### Mimir Configuration (mimir.yml)

```yaml
# Key settings for 30-day retention
multitenancy_enabled: false  # Uses "anonymous" tenant
limits:
  compactor_blocks_retention_period: 720h  # 30 days
  max_query_lookback: 720h                 # 30 days
  ingestion_rate: 50000                    # samples/sec
  max_global_series_per_user: 500000       # total series
```

---

## ğŸ”” Alerting Setup

GatewayZ uses **Grafana Alerting** (not Alertmanager) for notifications. Alerts are provisioned via YAML files and sent via email.

### Alert Categories

| Category | Severity | Description | Contact Point |
|----------|----------|-------------|---------------|
| **Traffic Anomalies** | Critical/Warning | Traffic spikes (3x+/2x baseline) | observatory-pool-critical/warning |
| **Error Rate Spikes** | Critical/Warning | Elevated error rates | observatory-pool-critical/warning |
| **Latency Anomalies** | Critical/Warning | P99 > 5s, degraded response times | observatory-pool-critical/warning |
| **Availability Drops** | Critical/Warning | Provider/service unavailability | observatory-pool-critical/warning |
| **Redis Issues** | Critical/Warning | Cache failures, memory issues | critical-email / ops-email |
| **SLO Burn Rate** | Critical/Warning | Error budget consumption | critical-email / ops-email |

### Contact Points Configuration

**File:** `grafana/provisioning/alerting/contact_points.yml`

```yaml
contactPoints:
  - name: ops-email
    receivers:
      - type: email
        settings:
          addresses: your-team@company.com
          singleEmail: false

  - name: critical-email
    receivers:
      - type: email
        settings:
          addresses: oncall@company.com
          singleEmail: false

  - name: observatory-pool-critical
    receivers:
      - type: email
        settings:
          addresses: alerts@company.com
```

### Notification Policies

**File:** `grafana/provisioning/alerting/notification_policies.yml`

Routes alerts to appropriate contact points based on labels:

| Matcher | Contact Point | Group Interval |
|---------|---------------|----------------|
| `severity=critical` | critical-email | 5m |
| `category=traffic_spike, severity=critical` | observatory-pool-critical | 5m |
| `category=error_rate_spike` | observatory-pool-critical/warning | 3-5m |
| `component=redis, severity=critical` | critical-email | 2m |
| `component=slo` | critical-email | 5m |

### Alert Rules

**Directory:** `grafana/provisioning/alerting/rules/`

| File | Alerts |
|------|--------|
| `traffic_anomalies.yml` | Traffic spikes, drops |
| `error_rate_anomalies.yml` | Error rate spikes by provider |
| `latency_anomalies.yml` | P99 latency spikes |
| `availability_anomalies.yml` | Provider availability drops |
| `redis_alerts.yml` | Redis cache issues |
| `slo_burn_rate_alerts.yml` | SLO violation alerts |
| `backend_alerts.yml` | Backend service health |
| `model_alerts.yml` | Model-specific issues |

### Setting Up Email Alerts

1. **Configure SMTP in docker-compose.yml:**
   ```yaml
   grafana:
     environment:
       - GF_SMTP_ENABLED=true
       - GF_SMTP_HOST=smtp.gmail.com:587
       - GF_SMTP_USER=your-email@gmail.com
       - GF_SMTP_PASSWORD=your-app-password
       - GF_SMTP_FROM_ADDRESS=grafana@gatewayz.ai
   ```

2. **Update contact_points.yml with your email addresses:**
   ```yaml
   contactPoints:
     - name: ops-email
       receivers:
         - type: email
           settings:
             addresses: your-team@company.com
   ```

3. **Test email delivery:**
   - Go to Grafana â†’ Alerting â†’ Contact points
   - Click "Test" on any contact point
   - Verify email is received

### Viewing Alerts

- **Grafana UI:** Alerting â†’ Alert rules
- **Prometheus UI:** http://localhost:9090/alerts
- **API:**
  ```bash
  # List firing alerts
  curl http://localhost:3000/api/alertmanager/grafana/api/v2/alerts \
    -H "Authorization: Bearer $GRAFANA_API_KEY"
  ```

---

## ğŸ§ª Testing & Quality Assurance

### Test Coverage

- **25+ Real API Endpoints** - Integration tests with performance validation
- **7 Production Dashboards** - Schema validation and configuration checks
- **90+ Test Methods** - Comprehensive coverage across all components
- **GitHub Actions Workflows** - Automated validation on every deployment

### Quick Testing Commands

```bash
# Setup (required once)
cp .env.example .env
# Edit .env and add your API keys

# Run all tests
pytest tests/ -v

# Dashboard validation
./scripts/validate_dashboards.sh strict

# Endpoint testing
export API_KEY="your_api_key"
./scripts/test_all_endpoints.sh "$API_KEY" https://api.gatewayz.ai

# Specific test categories
pytest tests/test_dashboards.py -v -m dashboard
pytest tests/test_api_endpoints.py -v -m endpoint
```

---

## ğŸš€ Deployment

### Railway Deployment

```bash
# 1. Push to Railway
git push railway main

# 2. Or use Railway CLI
railway up

# 3. Configure environment variables in Railway dashboard
FASTAPI_TARGET=api.gatewayz.ai:443
PROMETHEUS_INTERNAL_URL=http://prometheus.railway.internal:9090
MIMIR_INTERNAL_URL=http://mimir.railway.internal:9009
LOKI_URL=http://loki.railway.internal:3100
TEMPO_INTERNAL_URL=http://tempo.railway.internal:3200
```

### Docker Compose (Local)

```bash
# Start all services
docker compose up --build

# Start specific services
docker compose up grafana prometheus mimir

# View logs
docker compose logs -f grafana

# Stop all services
docker compose down

# Clean volumes (WARNING: deletes all data)
docker compose down -v
```

**ğŸ“– Deployment Guide:** [docs/deployment/RAILWAY_DEPLOYMENT_QUICK_START.md](docs/deployment/RAILWAY_DEPLOYMENT_QUICK_START.md)

---

## ğŸ“š Documentation

### Core Documentation

- **[Documentation Index](docs/docs-index.md)** - Start here for all docs
- **[Backend Integration](docs/backend/BACKEND_METRICS_REQUIREMENTS.md)** - Required metrics and instrumentation
- **[Railway Deployment](docs/deployment/RAILWAY_DEPLOYMENT_QUICK_START.md)** - Deploy to Railway
- **[Mimir Integration](MIMIR_INTEGRATION_SUMMARY.md)** - Horizontal scaling guide
- **[Troubleshooting](docs/troubleshooting/)** - Service-specific fix guides



---

## ğŸ› ï¸ Development

### Project Structure

```
railway-grafana-stack/
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”œâ”€â”€ model_performance/  # Model Performance metrics
â”‚   â”‚   â”œâ”€â”€ loki/               # Loki logs (pure logs)
â”‚   â”‚   â”œâ”€â”€ prometheus/         # Prometheus metrics
â”‚   â”‚   â”œâ”€â”€ tempo/              # Tempo traces (pure traces)
â”‚   â”‚   â””â”€â”€ mimir/              # Mimir long-term metrics
â”‚   â”œâ”€â”€ datasources/
â”‚   â”‚   â””â”€â”€ datasources.yml     # Prometheus, Mimir, Loki, Tempo
â”‚   â””â”€â”€ provisioning/
â”‚       â”œâ”€â”€ dashboards/
â”‚       â”‚   â””â”€â”€ dashboards.yml
â”‚       â””â”€â”€ alerting/
â”‚           â”œâ”€â”€ rules/
â”‚           â”‚   â””â”€â”€ redis_alerts.yml
â”‚           â””â”€â”€ notification_policies.yml
â”œâ”€â”€ prometheus/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ entrypoint.sh         # Environment-based configuration
â”‚   â”œâ”€â”€ prometheus.yml        # Scrape jobs + remote_write to Mimir
â”‚   â””â”€â”€ alert.rules.yml       # Alert rules
â”œâ”€â”€ mimir/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ mimir.yml             # Mimir configuration (30d retention)
â”œâ”€â”€ loki/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ loki.yml              # Loki configuration
â”œâ”€â”€ tempo/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ entrypoint.sh         # Environment-based configuration
â”‚   â””â”€â”€ tempo.yml             # Tempo configuration
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ pre-build-cleanup.sh  # Railway pre-deploy cleanup
â”‚   â””â”€â”€ ...                   # Other validation scripts
â”œâ”€â”€ tests/                    # Pytest test suite
â”œâ”€â”€ docs/                     # Documentation
â”œâ”€â”€ railway.toml              # Railway deployment configuration
â”œâ”€â”€ docker-compose.yml        # Local development
â””â”€â”€ README.md                 # This file
```

### Contributing

1. Create feature branch: `git checkout -b feature/my-feature`
2. Make changes and test locally with `docker compose up`
3. Run tests: `pytest tests/ -v`
4. Create pull request to `main`

---

## ğŸ“ Support & Resources

### External Documentation

- [Grafana Documentation](https://grafana.com/docs/grafana/latest/)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Mimir Documentation](https://grafana.com/docs/mimir/latest/)
- [Loki Documentation](https://grafana.com/docs/loki/latest/)
- [Tempo Documentation](https://grafana.com/docs/tempo/latest/)
- [OpenTelemetry Documentation](https://opentelemetry.io/docs/)
- [Railway Documentation](https://docs.railway.app/)

### Getting Help

- **Documentation Issues:** Check [docs/troubleshooting/](docs/troubleshooting/)
- **Backend Integration:** See [docs/backend/BACKEND_METRICS_REQUIREMENTS.md](docs/backend/BACKEND_METRICS_REQUIREMENTS.md)
- **Deployment Help:** Review [docs/deployment/RAILWAY_DEPLOYMENT_QUICK_START.md](docs/deployment/RAILWAY_DEPLOYMENT_QUICK_START.md)

---

## ğŸ“„ License

Proprietary - GatewayZ Network

---

**GatewayZ Observability Stack** Â· Enterprise-grade monitoring for AI infrastructure Â· Powered by Prometheus, Mimir, Loki, Tempo, and Grafana
